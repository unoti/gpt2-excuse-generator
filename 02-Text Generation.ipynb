{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "#import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Encode a text inputs\n",
    "text = \"Who was Jim Henson ? Jim Henson was a\"\n",
    "indexed_tokens = tokenizer.encode(text)\n",
    "\n",
    "# Convert indexed tokens in a PyTorch tensor\n",
    "tokens_tensor = torch.tensor([indexed_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Set the model in evaluation mode to deactivate the DropOut modules\n",
    "# This is IMPORTANT to have reproducible results during evaluation!\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "tokens_tensor = tokens_tensor.to('cuda')\n",
    "model.to('cuda')\n",
    "\n",
    "# Predict all tokens\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor)\n",
    "    predictions = outputs[0]\n",
    "\n",
    "# get the predicted next sub-word (in our case, the word 'man')\n",
    "predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
    "predicted_text = tokenizer.decode(indexed_tokens + [predicted_index])\n",
    "\n",
    "predicted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator:\n",
    "    def __init__(self):\n",
    "        # Load pre-trained model tokenizer (vocabulary)\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "        # Load pre-trained model (weights)\n",
    "        self.model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "        # Set the model in evaluation mode to deactivate the DropOut modules\n",
    "        # This is IMPORTANT to have reproducible results during evaluation!\n",
    "        self.model.eval()\n",
    "        # If you have a GPU, put everything on cuda\n",
    "        self.model.to('cuda')\n",
    "\n",
    "    \n",
    "    def generate_word(self, start_text):\n",
    "        \"\"\"\n",
    "        Generate one word (or sub-word, sometimes) to add onto some start text.\n",
    "        The generated word will contain a leader space if appropriate.\n",
    "        \"\"\"\n",
    "        # Encode text inputs\n",
    "        indexed_tokens = self.tokenizer.encode(start_text)\n",
    "        # Convert indexed tokens in a PyTorch tensor\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        # Move the tokens to the GPU.\n",
    "        tokens_tensor = tokens_tensor.to('cuda')\n",
    "        \n",
    "\n",
    "        # Predict all tokens\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor)\n",
    "            predictions = outputs[0]\n",
    "\n",
    "        # get the predicted next sub-word.\n",
    "        predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
    "        generated_word = self.tokenizer.decode(predicted_index)\n",
    "        return generated_word\n",
    "    \n",
    "    def generate(self, start_text, word_count=7):\n",
    "        text = start_text\n",
    "        for _ in range(word_count):\n",
    "            text += self.generate_word(text)\n",
    "        return text\n",
    "    \n",
    "    def generate_sentence(self, start_text, sentence_count=1, up_to_count = None):\n",
    "        if up_to_count:\n",
    "            sentence_count = random.randint(1, up_to_count)\n",
    "        sentence_count=2 # TEMPORARY\n",
    "        text = start_text\n",
    "        sentence = ''\n",
    "        for _ in range(sentence_count):\n",
    "            while (True):\n",
    "                word = self.generate_word(text)\n",
    "                text += word\n",
    "                sentence += word\n",
    "                if '.' in word:\n",
    "                    break\n",
    "        return sentence\n",
    "\n",
    "gen = TextGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' far'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.generate_word(\"Can't stop now; I've travelled so\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Can't stop now; I've travelled a lot. I've been to a lot of\""
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.generate(\"Can't stop now; I've travelled\",  10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My assignment was to wash the dishes.  I couldn't do that because I was too busy.               \""
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = gen.generate(\"My assignment was to wash the dishes.  I couldn't do that because\",20)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My assignment was to wash the dishes.  I couldn't do that because I was too busy.               I feel terrible about that because I didn't do it. \""
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text += \"I feel terrible about that because\"\n",
    "gen.generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlameModeMe:\n",
    "    my = 'my'\n",
    "    i = 'I'\n",
    "    me = 'me'\n",
    "\n",
    "class BlameModeYou:\n",
    "    my = 'your'\n",
    "    i = 'you'\n",
    "    me = 'you'\n",
    "\n",
    "class BlameModeTeam:\n",
    "    my = 'our'\n",
    "    i = 'we'\n",
    "    me = 'us'\n",
    "\n",
    "class BlameModeTeamBlameShift:\n",
    "    my = 'their'\n",
    "    i = 'they'\n",
    "    me = 'them'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTRO_TEXT = [\n",
    "    '[my] assignment was to',\n",
    "    '[I] was supposed to',\n",
    "    '[I] intended to',\n",
    "    '[my] goal was to',\n",
    "    '[my] dream, [my] destiny was to',\n",
    "    '[I] had every intention to'\n",
    "]\n",
    "\n",
    "HOWEVER_TEXT = [\n",
    "    \"Sadly, that didn't work out because\",\n",
    "    \"Unfortunately, there was a serious problem with that\",\n",
    "    \"[I] couldn't do that because\",\n",
    "]\n",
    "\n",
    "TASK_INTRO = [\n",
    "    'Things were going pretty well until [I] got to the part where [I] needed to',\n",
    "    '[I] hit a serious problem when [I] started to',\n",
    "    '[I] hit a major roadblock when [I] began to'\n",
    "]\n",
    "\n",
    "TASK_TRANSITION = [\n",
    "    'The problem was',\n",
    "    'What stopped [me] dead'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[I] couldn't do that because\""
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(HOWEVER_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You know that I would never do that'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'You know that [I] would never do that'.replace('[I]', 'I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExcuseSituation:\n",
    "    def __init__(self, text_generator, assignment, tasks=[], is_team=False, blame_others=False):\n",
    "        self.assignment = assignment\n",
    "        self.tasks = tasks\n",
    "        self.generator = text_generator\n",
    "        if is_team:\n",
    "            if blame_others:\n",
    "                mode = BlameModeTeamBlameShift\n",
    "            else:\n",
    "                mode = BlameModeTeam\n",
    "        else:\n",
    "            if blame_others:\n",
    "                mode = BlameModeYou\n",
    "            else:\n",
    "                mode = BlameModeMe\n",
    "        self.mode = mode\n",
    "    \n",
    "    def generate_excuse(self):\n",
    "        if random.random() < 0.5 or not self.tasks:\n",
    "            return self.generate_excuse_whole()\n",
    "        else:\n",
    "            return self.generate_excuse_task()\n",
    "        \n",
    "    def generate_excuse_task(self):\n",
    "        background = [random.choice(INTRO_TEXT), self.assignment, '.']\n",
    "        background += [random.choice(TASK_INTRO), random.choice(self.tasks), '.']\n",
    "        background += [random.choice(TASK_TRANSITION)]\n",
    "        background_text = self._list_to_text(background)\n",
    "        text = self.generator.generate_sentence(background_text, up_to_count=3)\n",
    "        return self._prep_result(background_text + text)\n",
    "        \n",
    "    def generate_excuse_whole(self):\n",
    "        # Lead-in text, setting up the situation.\n",
    "        background = [random.choice(INTRO_TEXT), self.assignment, '.']\n",
    "        background += [random.choice(HOWEVER_TEXT)]\n",
    "        \n",
    "        background_text = self._list_to_text(background)\n",
    "        text = self.generator.generate_sentence(background_text)\n",
    "        return self._prep_result(background_text + text)\n",
    "\n",
    "    def generate_excuses(self, count=5):\n",
    "        result = []\n",
    "        for _ in range(count):\n",
    "            result.append(self.generate_excuse())\n",
    "        return result\n",
    "            \n",
    "    def _list_to_text(self, chunk_list):\n",
    "        words = []\n",
    "        for entry in chunk_list:\n",
    "            entry = entry.replace('[I]', self.mode.i)\n",
    "            entry = entry.replace('[my]', self.mode.my)\n",
    "            entry = entry.replace('[me]', self.mode.me)\n",
    "            words.append(entry)\n",
    "        return ' '.join(words)\n",
    "    \n",
    "    def _prep_result(self, excuse_text):\n",
    "        return excuse_text[0].upper() + excuse_text[1:] # Capitalize sentence\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I was supposed to prepare a nice dinner for you for Valentine's day . I hit a serious problem when I started to plan the menu . What stopped me dead in my tracks was the fact that I had to make a decision that I didn't want to make. I had to make a decision that I didn't want to make.\"]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ExcuseSituation(gen, assignment=\"prepare a nice dinner for you for Valentine's day\", tasks=[\n",
    "    'plan the menu',\n",
    "    'go to the grocery store to buy the ingredients',\n",
    "    'cook it up',\n",
    "    'plate the meal in an attractive way',\n",
    "])\n",
    "s.generate_excuses(count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fight the Repetition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GPT2 Issue: Repetition](https://github.com/huggingface/transformers/issues/1725).  Solution is to use *temperarture*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new TextGenerator with a temperature parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class TextGenerator:\n",
    "    def __init__(self):\n",
    "        # Load pre-trained model tokenizer (vocabulary)\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "        # Load pre-trained model (weights)\n",
    "        self.model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "        # Temperature adds randomness and unpredictability.\n",
    "        self.temperature = random.choice([0.8, 0.8, 0.8, 0.9, 0.7])\n",
    "\n",
    "        # Set the model in evaluation mode to deactivate the DropOut modules\n",
    "        # This is IMPORTANT to have reproducible results during evaluation!\n",
    "        self.model.eval()\n",
    "        # If you have a GPU, put everything on cuda\n",
    "        self.model.to('cuda')\n",
    "\n",
    "    \n",
    "    def generate_word(self, start_text):\n",
    "        \"\"\"\n",
    "        Generate one word (or sub-word, sometimes) to add onto some start text.\n",
    "        The generated word will contain a leader space if appropriate.\n",
    "        \"\"\"\n",
    "        # Encode text inputs\n",
    "        indexed_tokens = self.tokenizer.encode(start_text)\n",
    "        # Convert indexed tokens in a PyTorch tensor\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        # Move the tokens to the GPU.\n",
    "        tokens_tensor = tokens_tensor.to('cuda')\n",
    "        \n",
    "\n",
    "        # Predict all tokens\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor)\n",
    "            # Use temperature to add more chaos into the selection of words.\n",
    "            next_token_logits = outputs[0][:, -1, :] / self.temperature   # <--- Temperature\n",
    "            next_token = torch.multinomial(F.softmax(next_token_logits, dim=-1), num_samples=1) # <-- Temperature\n",
    "\n",
    "        # get the predicted next sub-word.\n",
    "        generated_word = self.tokenizer.decode(next_token)\n",
    "        return generated_word\n",
    "    \n",
    "    def generate(self, start_text, word_count=7):\n",
    "        text = start_text\n",
    "        for _ in range(word_count):\n",
    "            text += self.generate_word(text)\n",
    "        return text\n",
    "    \n",
    "    def generate_sentence(self, start_text, sentence_count=1, up_to_count = None):\n",
    "        if up_to_count:\n",
    "            sentence_count = random.randint(1, up_to_count)\n",
    "        sentence_count=2 # TEMPORARY\n",
    "        text = start_text\n",
    "        sentence = ''\n",
    "        for _ in range(sentence_count):\n",
    "            while (True):\n",
    "                word = self.generate_word(text)\n",
    "                text += word\n",
    "                sentence += word\n",
    "                if '.' in word:\n",
    "                    break\n",
    "        return sentence\n",
    "\n",
    "gen = TextGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I was supposed to prepare a nice dinner for you for Valentine's day . Sadly, that didn't work out because I didn't feel like eating. In fact, I think pancakes are the best dessert I've ever had.\",\n",
       " \"I had every intention to prepare a nice dinner for you for Valentine's day . Sadly, that didn't work out because my ass was still sore and I was already too sad and hungry to eat. So I decided to come up with an excuse to drive home, but then, having just finished my first breakfast, I ran into my friend, who just happened to be the new president of the United States.\",\n",
       " \"My assignment was to prepare a nice dinner for you for Valentine's day . Sadly, that didn't work out because I was actually planning on baking this very day. One thing I had to think about was that if you run out of time and the oven starts to bake, you might want to wait till you can bake it.\",\n",
       " \"I intended to prepare a nice dinner for you for Valentine's day . Sadly, that didn't work out because I was home from work on Monday and I didn't smell anything. I checked the refrigerator and found almost nothing.\"]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ExcuseSituation(gen, assignment=\"prepare a nice dinner for you for Valentine's day\", tasks=[\n",
    "    'plan the menu',\n",
    "    'go to the grocery store to buy the ingredients',\n",
    "    'cook it up',\n",
    "    'plate the meal in an attractive way',\n",
    "])\n",
    "s.generate_excuses(count=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crazy stuff this came up with:\n",
    "* My dream, my destiny was to prepare a nice dinner for you for Valentine\\'s day . I hit a major roadblock when I began to plan the menu . What stopped me dead in my tracks?\" What stopped me dead in my tracks?\" \"You know what, **I want you to live inside my house for a while**, so you can **enjoy my calm and wayward, hard-working, and true love**.\"\n",
    "* I was supposed to prepare a nice dinner for you for Valentine's day . Unfortunately, there was a serious problem with that dinner. My girlfriend thought I was **acting out as a man** so I had to be careful, but it turned out that there was a real problem.\n",
    "* My assignment was to prepare a nice dinner for you for Valentine's day . Things were going pretty well until I got to the part where I needed to go to the grocery store to buy the ingredients . The problem was, I knew **there was already so much food in the fridge**. I had to look around to find the ingredients I needed and it was only over a month later when I got home that **I found the ingredient list for Trader Joe's frozen food**.\n",
    "* I had every intention to prepare a nice dinner for you for Valentine's day . I hit a major roadblock when I began to plan the menu . What stopped me dead in my tracks was my own faraway world of extremities. **How could I conclude that food would be a primary way to trigger deep emotional cycles of desire?**\n",
    "* My goal was to prepare a nice dinner for you for Valentine\\'s day . I hit a serious problem when I started to go to the grocery store to buy the ingredients . The problem was that I had no idea how to prepare it. **I set aside my grocery money and said to myself, \"where have I seen this** and how can I prove to myself how to prepare it with my own money?\" **Now buy some flowers and you can actually have a good time.**\n",
    "* My dream, my destiny was to prepare a nice dinner for you for Valentine's day . Sadly, that didn't work out because **I had wasted my money and we both spent a lot**. Therefore, **I did all of my annual shopping for my daughter, and it has been a pleasure to watch her grow into a confident, confident young man.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it a little crazier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.temperature = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"My goal was to prepare a nice dinner for you for Valentine's day . I couldn't do that because I was pregnant on this hunt myself so I haven't even tried this article yet. I believe her 10th birthday is around 3 hour away so we have a tough time on her day.\",\n",
       " \"I had every intention to prepare a nice dinner for you for Valentine's day . I hit a major roadblock when I began to plan the menu . The problem was, they didn't plan it all as I had planned it. But I decided to use it as I needed.\",\n",
       " \"I had every intention to prepare a nice dinner for you for Valentine's day . Things were going pretty well until I got to the part where I needed to plate the meal in an attractive way . What stopped me dead in my tracks was my insecurity drinking in too many restaurants and and I almost had a bath under the table because even though I ate my meals in strange and disgusting directions by empty, dank, miserable spaces like cafÃ©illes, I knew quite well that I needed to see you again.\\n\\n In reality I could never live without good food or a decent night's sleep.\",\n",
       " \"I had every intention to prepare a nice dinner for you for Valentine's day . Things were going pretty well until I got to the part where I needed to go to the grocery store to buy the ingredients . The problem was that I didn't have the right form of paper to make some arrangements, so I flubbed in a bunch of other complexions on my 'twins, making sure it wasn't messy. I found that it was a pretty easy double job.\"]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ExcuseSituation(gen, assignment=\"prepare a nice dinner for you for Valentine's day\", tasks=[\n",
    "    'plan the menu',\n",
    "    'go to the grocery store to buy the ingredients',\n",
    "    'cook it up',\n",
    "    'plate the meal in an attractive way',\n",
    "])\n",
    "s.generate_excuses(count=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
